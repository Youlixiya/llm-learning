## 5. Agent 与工具调用：让模型学会“自己动手查资料和算东西”

到目前为止，我们已经有了：

- 能对话和生成内容的开源大模型（可选 LoRA 微调）；
- 能“先检索再回答”的 RAG 知识库问答系统。

本章我们进一步让模型具备“调用工具”的能力，使其可以：

> 根据任务需要，自动决定是直接回答、查知识库，还是做计算，再综合给出最终答案。

---

### 5.1 什么是 Agent ？

在本教程中，我们用一个工程上足够实用的定义：

> **Agent = LLM + 一组可调用的工具 + 决策循环。**

其中：

- LLM 负责“理解任务 + 规划下一步要做什么”；
- 工具负责执行具体动作，例如：
  - 搜索文档 / 调用 RAG；
  - 计算数学表达式；
  - 调接口、查数据库、发请求等；
- 决策循环负责：
  - 把工具使用结果反馈给 LLM；
  - 让 LLM 基于新信息继续推理，直到给出最终答案。

在工业实践中，Agent 通常会结合工作流编排、调用链监控、安全隔离等一整套基础设施。  
在本教程里，我们从一个 **最小可运行版本** 开始：只实现几个简单工具 + 单轮决策循环。

---

### 5.2 本章代码结构与运行方式

本章相关代码位于：

- `src/agents/simple_agent.py`：一个最小可运行的 Agent 示例，支持：
  - `search_docs`：在本地 RAG 语料目录里做简单关键词搜索；
  - `calculator`：执行简单的数学计算；
  - `get_time`：获取当前时间；
  - 以及一个 LLM 驱动的决策过程（用 JSON 协议描述工具调用）。

一键运行示例脚本：

- `scripts/run_agent_demo.sh`：启动一个简单的命令行 Agent，对话式地执行指令。

#### 5.2.1 启动示例 Agent

在项目根目录下：

```bash
python src/agents/simple_agent.py \
  --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct
```

或者使用脚本：

```bash
bash scripts/run_agent_demo.sh
```

运行后你会看到一个交互式命令行提示符，例如：

```text
输入你的指令（输入 exit 退出）> 
```

你可以尝试：

- `帮我用要点列出这套 LLM 教程推荐的学习路线，并按优先级排序`（模型可能选择调用 `search_docs`）；
- `请计算：(3 + 5) * 12 / 4`（模型可能选择调用 `calculator`）；
- `现在的日期和时间是多少？`（模型可能选择调用 `get_time`）。

---

### 5.3 工具协议与 JSON 格式

在 `simple_agent.py` 中，我们约定了一套非常简单的“工具调用协议”：

1. Agent 会把可用工具的说明以自然语言 + JSON 模板的形式告诉 LLM；
2. 当 LLM 认为需要调用工具时，必须输出类似这样的 JSON：

```json
{"type": "tool_call", "tool": "calculator", "arguments": {"expression": "(3 + 5) * 12 / 4"}}
```

3. 当 LLM认为已经获得足够信息、可以给出最终答案时，则输出：

```json
{"type": "final_answer", "answer": "最终回答内容"}
```

Agent 通过解析这段 JSON 来决定：

- 是去执行某个 Python 函数（工具），然后把结果再反馈给 LLM；
- 还是直接把 `answer` 展示给用户。

> 这个协议可以看作是 “手写版的 function calling / tool calling”，  
> 方便你理解其内部机制，而不依赖任何高级框架。

---

### 5.4 决策循环：一轮工具调用 + 最终回答

为了简单起见，本示例实现的是“最多一轮工具调用”的决策流程：

1. 把用户问题和工具说明一起交给 LLM；
2. LLM 返回一个 JSON：
   - 如果 `type = "final_answer"`，直接输出结果；
   - 如果 `type = "tool_call"`，则：
     1. 调用对应的 Python 工具函数，得到结果文本；
     2. 把“工具调用及结果”作为新一轮输入，要求 LLM 基于结果输出最终回答；
3. 将最终回答打印到命令行。

这种设计足以覆盖很多“查一次资料 / 算一次东西再回答”的日常需求，也便于你逐步扩展成多轮、多工具的复杂 Agent。

---

### 5.5 工程实践中的扩展方向

如果你打算在生产环境中使用 Agent 思路，可以进一步思考：

- **安全性**
  - 工具调用必须做严格的参数校验和权限隔离；
  - 对类似 `calculator` 这样的执行逻辑，要注意避免注入风险。
- **可观测性**
  - 记录每一次工具调用（输入 / 输出 / 耗时）和 LLM 决策轨迹；
  - 方便排查“模型为什么会做出这个决定”。
- **确定性与兜底**
  - 对关键业务流程，可以通过规则或工作流把“工具调用顺序”固定下来；
  - LLM 负责补充自然语言解释，而不是完全自治决策。

---

### 5.6 小结

本章我们实现了一个最小化的 Agent 示例，它具备：

- 一组用 Python 实现的简单工具（搜索、计算、时间）；
- 一套基于 JSON 的工具调用协议；
- 一个“最多一轮工具调用 + 最终回答”的决策循环。

结合前几章的指令微调和 RAG，你已经可以：

- 用 LoRA 定制一个更贴合自己需求的“基座助手”；
- 用 RAG 为它接入企业/个人知识库；
- 用 Agent 框架让它学会“该查资料时查资料，该算东西时算东西”。

在真实项目中，你可以在这个基础上持续扩展工具集和决策逻辑，把它演化成一个真正可用的 LLM 应用平台。

